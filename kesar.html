<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Problem Solving and Algorithms</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f9f9f9;
            color: #333;
        }

        h1 {
            color: #0056b3;
        }

        h2 {
            color: #56284b;
            border-bottom: 2px solid #c6efed;
            padding-bottom: 5px;
        }

        ul {
            padding-left: 20px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        table th, table td {
            border: 1px solid #ccc;
            padding: 10px;
            text-align: left;
        }

        table th {
            background-color: #bb8cde;
            color: #fff;
        }
    </style>
</head>

<body>
    <h1>Problem Solving and Algorithms</h1>

    <h2>1. Kinds of Problems We See in Nature</h2>
    <ul>
        <li><strong>Recursion</strong>: Recursion: break down a problem in simpler instances.
            <ul>
                <li> for example Fibonacci sequence, tower of Brahma.</li>
            </ul>
        </li>
        <li><strong>Iteration</strong>: solving a problem step by step using loops.
            <ul>
                <li>e.g, the sum of numbers or traversing arrays.</li>
            </ul>
        </li>
        <li><strong>Backtracking</strong>: trying all solutions while discarding the invalid options.
            <ul>
                <li>examples include the N-Queens problem, maze navigation, and sudoku.</li>
            </ul>
        </li>
    </ul>

    <h2>2. Space and Time Complexity</h2>
    <ul>
        <li><strong>Time Efficiency</strong>: excess time consumed by the algorithm to complete.</li>
        <li><strong>Space Efficiency</strong>: additional space used up by program.</li>
        <li><strong>Growth Rates</strong>: Algorithms are classified by growth rates like:
            <ul>
                <li>O(1): Constant time.</li>
                <li>O(n²): Quadratic time.</li>
            </ul>
        </li>
    </ul>

    <h2>3. Takeaway from Different Design Principles</h2>
    <ul>
        <li><strong>Dynamic Programming</strong>: Avoids redundant calculations by storing intermediate results.
            <ul>
                <li>Example: Knapsack problem.</li>
            </ul>
        </li>
        <li><strong>Divide-and-Conquer</strong>: Breaks problems into smaller, manageable parts.
            <ul>
                <li>Example: Merge sort, quick sort.</li>
            </ul>
        </li>
    </ul>

    <h2>4. Hierarchical Data and Data Structures</h2>
    <ul>
        <li><strong>Binary Trees</strong>: Store data hierarchically, such as parent connected to child.</li>
        <li><strong>Binary Search Trees (BST)</strong>: Enable efficient searching and insertion.</li>
        <li><strong>Self-Balancing Trees</strong>: Ensure consistent performance (e.g., Heap, AVL Trees, Red-Black Trees).</li>
        <li><strong>Heaps</strong>: Ideal for priority queues and self-balancing.</li>
        <li><strong>Tries</strong>: Useful for autocomplete or dictionary lookups but occupy more space.</li>
    </ul>

    <h2>5. Array Query Algorithms</h2>
    <ul>
        <li><strong>Prefix Sum Arrays</strong>: Allow quick cumulative sum computations.</li>
        <li><strong>Fenwick Trees</strong>: Provide efficient prefix sums and updates.</li>
        <li><strong>Segment Trees</strong>: Offer range queries and updates.</li>
        <li><strong>Lookup Tables</strong>: Allow fast retrieval of precomputed results.</li>
    </ul>

    <h2>6. Difference Between Trees and Graphs</h2>
    <table>
        <thead>
            <tr>
                <th>Trees</th>
                <th>Graphs</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Hierarchical, no cycles.</td>
                <td>Can be non-hierarchical, may have cycles.</td>
            </tr>
            <tr>
                <td>Used in family trees, file directories.</td>
                <td>Used in networks, social graphs.</td>
            </tr>
            <tr>
                <td>Traversals include Preorder, Inorder, Postorder.</td>
                <td>Traversals include DFS and BFS.</td>
            </tr>
        </tbody>
    </table>

    <h2>7. Sorting and Searching Fundamentals</h2>
    <ul>
        <li><strong>Sorting Algorithms</strong>: Bubble sort, merge sort, quick sort.</li>
        <li><strong>Searching Algorithms</strong>:
            <ul>
                <li>Linear Search: Works on unsorted data.</li>
                <li>Binary Search: Requires sorted data.</li>
            </ul>
        </li>
    </ul>

    <h2>8. Graph Algorithms for Network Problems</h2>
    <ul>
        <li><strong>Minimum Spanning Trees (MST)</strong>: Kruskal’s and Prim’s algorithms optimize networks, like electrical grids.</li>
        <li><strong>Shortest Path Algorithms</strong>:
            <ul>
                <li>Dijkstra’s Algorithm: Vital for routing and navigation systems.</li>
                <li>Bellman-Ford Algorithm: Handles graphs with negative weights.</li>
            </ul>
        </li>
    </ul>
</body>

</html>
